import pandas as pd
import sqlite3
import re
import unicodedata

# ==========
# 1. Excel èª­ã¿è¾¼ã¿
# ==========

INPUT_EXCEL = "æˆæ¥­æ¦‚è¦.xlsx"   # â† è‡ªåˆ†ã®ãƒ•ã‚¡ã‚¤ãƒ«åã«åˆã‚ã›ã¦å¤‰æ›´

df = pd.read_excel(INPUT_EXCEL, header=5)
df = df.dropna(how="all")
# ã‚»ãƒ«çµåˆéƒ¨åˆ†ï¼ˆåŒºåˆ†ãªã©ï¼‰ã‚’ç›´å‰ã®å€¤ã§åŸ‹ã‚ã‚‹ï¼ˆæ¨å¥¨ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰
df = df.ffill()

# ==========
# 2. æ›œæ—¥ãƒ»æ™‚é™ã®è§£æãƒ­ã‚¸ãƒƒã‚¯
# ==========

WEEKDAYS = "æœˆç«æ°´æœ¨é‡‘åœŸæ—¥"

def parse_day_period(line):
    """
    æ›œæ—¥ + æ™‚é™ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦ (day, period) ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™ã€‚
    ä¾‹ï¼š
    æœˆ3 â†’ [(æœˆ, 3)]
    æœ¨4.5 â†’ [(æœ¨,4),(æœ¨,5)]
    é‡‘2ãƒ»3 â†’ åŒä¸Š
    æœˆ34 â†’ [(æœˆ,3),(æœˆ,4)]
    é‡‘2-4 â†’ [(é‡‘,2),(é‡‘,3),(é‡‘,4)]
    """
    def to_hankaku(s):
        return unicodedata.normalize('NFKC', s)
    if not isinstance(line, str):
        return None
    line = line.strip()
    if not line or line[0] not in WEEKDAYS:
        return None
    day = to_hankaku(line[0])
    rest = to_hankaku(line[1:])
    rest = rest.replace('ï¼','.') \
               .replace('ãƒ»','.') \
               .replace('ï½¥','.')
    # ç¯„å›²æŒ‡å®šï¼ˆ3-5ï¼‰
    if '-' in rest:
        parts = rest.split('-')
        if len(parts) == 2 and parts[0].isdigit() and parts[1].isdigit():
            s, e = int(parts[0]), int(parts[1])
            return [(day, to_hankaku(str(p))) for p in range(s, e+1)]
        return None
    # åŒºåˆ‡ã‚Šè¨˜å·ï¼ˆ4.5ï¼‰
    if '.' in rest:
        toks = rest.split('.')
        periods = [int(t) for t in toks if t.isdigit()]
        return [(day, to_hankaku(str(p))) for p in periods] if periods else None
    # ä¾‹ï¼š34 â†’ 3,4
    if rest.isdigit() and len(rest) >= 2:
        return [(day, to_hankaku(ch)) for ch in rest]
    # å˜ä¸€ï¼ˆ4ï¼‰
    if rest.isdigit():
        return [(day, to_hankaku(rest))]
    return None


def parse_special(line):
    """ç‰¹åˆ¥ãƒ¯ãƒ¼ãƒ‰ï¼ˆé›†ä¸­ / éš”é€± / æŒ‡å°æ•™å“¡ / 1å­¦æœŸ / 2å­¦æœŸï¼‰"""
    if not isinstance(line, str):
        return None
    specials = ["é›†ä¸­", "éš”é€±", "æŒ‡å°æ•™å“¡", "1å­¦æœŸ", "2å­¦æœŸ", "æŒ‡å°æ•™å“¡ã®æŒ‡ç¤ºã«ã‚ˆã‚‹"]
    for s in specials:
        if s in line:
            return s
    return None


def parse_room(line):
    """æ•™å®¤æƒ…å ±ï¼ˆ201, 202, 509, å·¥æˆ¿, ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ«ãƒ¼ãƒ , 113ä»–ï¼‰"""
    def to_hankaku(s):
        return unicodedata.normalize('NFKC', s)
    if not isinstance(line, str):
        return None, None
    line = line.strip()
    if not line:
        return None, None
    m = re.match(r"(\d+)(ä»–)?", line)
    if m:
        return to_hankaku(m.group(1)), ("ä»–" if m.group(2) else None)
    # å·¥æˆ¿ãƒ»ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ«ãƒ¼ãƒ ãƒ»æ•™å®¤å
    known_rooms = ["å·¥æˆ¿", "ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ«ãƒ¼ãƒ "]
    if line in known_rooms:
        return to_hankaku(line), None
    return to_hankaku(line), None


def parse_cell(cell):
    """
    ã€Œæ›œæ™‚é™ï¼‹æ•™å®¤ã€ã‚»ãƒ«å…¨ä½“ã‚’è§£æã—ã¦è¿”ã™ã€‚
    è¿”ã‚Šå€¤ï¼š[(day, period, room, remarks), ...]
    """
    results = []
    day_periods = []
    rooms = []
    remarks = []

    # è¤‡æ•°è¡Œã®ã‚»ãƒ«ã‚’è¡Œã”ã¨ã«å‡¦ç†
    import unicodedata
    def to_hankaku(s):
        return unicodedata.normalize('NFKC', s)

    results = []
    last_day_periods = []
    remarks = []

    import re
    raw = str(cell)
    # ã€Œæ›œæ—¥ï¼‹æ™‚é™ï¼‹æ•™å®¤ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ã«è©²å½“ã™ã‚‹å ´åˆã®ã¿åˆ†å‰²
    # ä¾‹: æœˆ3 316, æœˆï¼”ã€€ï¼“ï¼‘ï¼–, æœˆ3\n316 ãªã©
    # æ›œæ—¥1æ–‡å­—ï¼‹æ•°å­—ãŒå«ã¾ã‚Œã¦ã„ã‚Œã°åˆ†å‰²å¯¾è±¡ã¨ã¿ãªã™
    if re.search(r'[æœˆç«æ°´æœ¨é‡‘åœŸæ—¥][0-9ï¼-ï¼™]', raw):
        # æ”¹è¡Œãƒ»å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ãƒ»ã‚¿ãƒ–ã§åˆ†å‰²
        split_pattern = r'[\n\u3000\t]+'
        lines = [to_hankaku(l.strip()) for l in re.split(split_pattern, raw) if l.strip()]
    else:
        # ãã‚Œä»¥å¤–ã¯å¾“æ¥é€šã‚Š1è¡Œã¨ã—ã¦æ‰±ã†
        lines = [to_hankaku(raw.strip())] if raw.strip() else []

    for line in lines:
        # ç‰¹æ®Šãƒ¯ãƒ¼ãƒ‰
        sp = parse_special(line)
        if sp:
            remarks.append(sp)
            continue

        # æ›œæ—¥ãƒ»æ™‚é™
        dp = parse_day_period(line)
        if dp:
            last_day_periods = dp
            continue

        # æ•™å®¤
        room, rem = parse_room(line)
        if room:
            # ç›´å‰ã®æ›œæ—¥ãƒ»æ™‚é™ã¨ãƒšã‚¢ã«ã™ã‚‹
            if last_day_periods:
                for day, period in last_day_periods:
                    results.append((day, period, room, ", ".join(remarks) if remarks else None))
                last_day_periods = []
            else:
                results.append((None, None, room, ", ".join(remarks) if remarks else None))
            if rem:
                remarks.append(rem)
            continue

    # æ®‹ã£ãŸæ›œæ—¥ãƒ»æ™‚é™ã ã‘
    if last_day_periods:
        for day, period in last_day_periods:
            results.append((day, period, None, ", ".join(remarks) if remarks else None))

    # ä½•ã‚‚ãªã‘ã‚Œã°remarksã ã‘
    if not results:
        results.append((None, None, None, ", ".join(remarks) if remarks else None))

    return results
# ==========

DB_PATH = "courses.db"

conn = sqlite3.connect(DB_PATH)
cur = conn.cursor()

# ãƒ†ãƒ¼ãƒ–ãƒ«ä½œã‚Šç›´ã—
cur.executescript("""
DROP TABLE IF EXISTS courses;
DROP TABLE IF EXISTS course_times;
DROP TABLE IF EXISTS course_instructors;

CREATE TABLE courses (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    category TEXT,
    code TEXT,
    title TEXT,
    credits TEXT,
    grade TEXT,
    required_or_choice TEXT,
    semester TEXT,
    description TEXT,
    note TEXT
);

CREATE TABLE course_times (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    course_id INTEGER,
    day TEXT,
    period TEXT,
    room TEXT,
    remarks TEXT
);

CREATE TABLE course_instructors (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    course_id INTEGER,
    instructor TEXT
);
""")


# ==========
# 4. ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥
# ==========

for _, row in df.iterrows():
    if _ == 2:  # 3è¡Œç›®ï¼ˆ0å§‹ã¾ã‚Šï¼‰
        print("Excelã‚»ãƒ«å†…å®¹:", row.get("æ›œæ™‚é™\næ•™  å®¤", ""))

    # courses ã¸
    # ã‚«ãƒ©ãƒ åã®å­˜åœ¨ç¢ºèªã¨å‹å¤‰æ›
    def safe_get(row, key):
        return str(row[key]) if key in row and not pd.isna(row[key]) else None

    # å®Ÿéš›ã®Excelã‚«ãƒ©ãƒ åã«åˆã‚ã›ã¦ãƒãƒƒãƒ”ãƒ³ã‚°
    data = (
        safe_get(row, "åŒºåˆ†"),
        safe_get(row, "ç§‘ç›®\nç•ªå·"),
        safe_get(row, "æˆæ¥­ç§‘ç›®"),
        safe_get(row, "å˜ä½æ•°"),
        safe_get(row, "æ¨™æº–å±¥ä¿®å¹´æ¬¡"),
        safe_get(row, "å¿…ä¿®\nãƒ»\né¸æŠ"),
        safe_get(row, "å®Ÿæ–½å­¦æœŸ"),
        safe_get(row, "æˆã€€ã€€æ¥­ã€€ã€€æ¦‚ã€€ã€€è¦"),
        safe_get(row, "ã€€ã€€å‚™ã€€è€ƒ\n(å¯¾è±¡å°‚æ”»ã€æ•™è·å…è¨±\n ã®æ•™ç§‘ç­‰)")
    )

    c = cur.execute("""
        INSERT INTO courses (
            category, code, title, credits, grade,
            required_or_choice, semester, description, note
        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
    """, data)

    course_id = c.lastrowid

    # course_times ã¸ï¼ˆå®Ÿéš›ã®ã‚«ãƒ©ãƒ åã§å‚ç…§ï¼‰
    time_entries = parse_cell(row.get("æ›œæ™‚é™\næ•™  å®¤", ""))
    for day, period, room, remarks in time_entries:
        cur.execute("""
            INSERT INTO course_times (course_id, day, period, room, remarks)
            VALUES (?, ?, ?, ?, ?)
        """, (course_id, day, period, room, remarks))

    # course_instructors ã¸ï¼ˆå®Ÿéš›ã®ã‚«ãƒ©ãƒ åã§å‚ç…§ï¼‰
    insts = re.split(r"[,ã€ï¼Œ/ãƒ»ï½¥\n]+", str(row.get("æ‹…å½“æ•™å“¡", "")))
    for inst in [i.strip() for i in insts if i.strip()]:
        # æ•™å“¡åã‚‚åŠè§’æ­£è¦åŒ–
        inst_hankaku = unicodedata.normalize('NFKC', inst)
        cur.execute("""
            INSERT INTO course_instructors (course_id, instructor)
            VALUES (?, ?)
        """, (course_id, inst_hankaku))

conn.commit()
conn.close()

print("ğŸ‰ SQLite ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç”Ÿæˆå®Œäº†ï¼š", DB_PATH)